{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('HerMajestySpeechesDataset/train.txt', 'r', encoding='utf-8')\n",
    "# text = f.read()\n",
    "texts = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "2361"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts as IDs: [[1, 180, 998, 4, 38, 583, 40, 2093, 2094, 20, 1164, 529], [20, 8, 162, 245, 7, 999, 24, 423, 1165, 4, 17, 19], [67, 194, 780], [1, 354, 2, 6, 1346, 721, 52, 584, 39, 212, 1, 296, 2, 530, 207, 1000], [1, 180, 67, 194, 5, 780, 2095, 20, 531, 116, 871, 3, 246], [1, 194, 48, 2096, 5, 2950, 1166, 5, 150, 223, 195, 490, 532, 2097, 196, 20, 6, 2951, 2952], [7, 12, 1167, 204, 872, 4, 113, 9, 454, 186, 297, 585, 1, 258, 10, 110, 204], [57, 2, 1, 454, 9, 28, 49, 648, 19, 9, 78, 10, 65, 11, 1, 311, 2, 67], [16, 270, 6, 58, 82, 7, 781, 4, 455, 2098, 1, 2953, 2, 1, 355, 3, 213, 9, 873, 48, 491, 4, 236, 128, 3, 492, 4, 6, 874, 41], [1, 354, 2, 782, 2099, 2954, 15, 456, 4, 19, 42, 491, 247, 3, 90, 1, 68, 2955, 10, 140]]\n",
      "IDs back to texts: [\"the queen's messages to those celebrating their 90th birthdays on 21 april\", 'on this shared occasion i send my warm congratulations to you all', 'christmas broadcast 2006', 'the birth of a baby brings great happiness but then the business of growing up begins', \"the queen's christmas broadcast in 2006 focused on understanding between faiths and generations\", 'the broadcast was filmed in southwark cathedral in london where her majesty met schoolchildren working on a nativity collage', 'i have lived long enough to know that things never remain quite the same for very long', 'one of the things that has not changed all that much for me is the celebration of christmas', 'it remains a time when i try to put aside the anxieties of the moment and remember that christ was born to bring peace and tolerance to a troubled world', 'the birth of jesus naturally turns our thoughts to all new born children and what the future holds for them']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts) \n",
    "\n",
    "texts2ids = tokenizer.texts_to_sequences(texts)\n",
    "print (\"Texts as IDs:\", texts2ids[:10])\n",
    "ids2texts = tokenizer.sequences_to_texts(texts2ids)\n",
    "print (\"IDs back to texts:\", ids2texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2294\n"
     ]
    }
   ],
   "source": [
    "print(len(texts2ids))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{(1, 2): {}, (3, 4): {}, (5, 6): {}}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {x:{} for x in [(1,2),(3,4),(5,6)]}\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{(1, 2): {'a': 1, 'b': 2}, (3, 4): {'a': 3, 'b': 4}, (5, 6): {}}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(1,2)] = {'a':1, 'b':2}\n",
    "test[(3,4)] = {'a':3, 'b':4}\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocurrency_example = {\n",
    "        '': {'a':1, 'b':2},\n",
    "        'a': {'b': 1, 'c': 1},\n",
    "        ('a','b'): {'c': 1},\n",
    "        ('b','c'): {'a': 2, 'd': 1},\n",
    "        ('c','d'): {'a': 1, 'b': 1, 'c': 1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toyLM_ngram(ngram_list, ngram_sizes=[2]):\n",
    "    table_list = []\n",
    "    for size in ngram_sizes:\n",
    "        oc_table = {}\n",
    "        for i in range(len(ngram_list)-size):\n",
    "            current_ngram = ngram_list[i:i+size]\n",
    "            for current_ngram in ngram_list:\n",
    "                if current_ngram in oc_table:\n",
    "                    oc_table[current_ngram] += 1\n",
    "                else:\n",
    "                    oc_table[current_ngram] = 1\n",
    "        table_list.append(oc_table)\n",
    "        print(oc_table)\n",
    "    return table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 123, 180: 41, 998: 41, 4: 82, 38: 41, 583: 41, 40: 41, 2093: 41, 2094: 41, 20: 82, 1164: 41, 529: 41, 8: 41, 162: 41, 245: 41, 7: 41, 999: 41, 24: 41, 423: 41, 1165: 41, 17: 41, 19: 41, 67: 41, 194: 41, 780: 41, 354: 41, 2: 82, 6: 41, 1346: 41, 721: 41, 52: 41, 584: 41, 39: 41, 212: 41, 296: 41, 530: 41, 207: 41, 1000: 41}\n",
      "[{1: 123, 180: 41, 998: 41, 4: 82, 38: 41, 583: 41, 40: 41, 2093: 41, 2094: 41, 20: 82, 1164: 41, 529: 41, 8: 41, 162: 41, 245: 41, 7: 41, 999: 41, 24: 41, 423: 41, 1165: 41, 17: 41, 19: 41, 67: 41, 194: 41, 780: 41, 354: 41, 2: 82, 6: 41, 1346: 41, 721: 41, 52: 41, 584: 41, 39: 41, 212: 41, 296: 41, 530: 41, 207: 41, 1000: 41}]\n"
     ]
    }
   ],
   "source": [
    "print(toyLM_ngram(texts2ids[0]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def get_ngrams(frase, size=2):\n",
    "    for i in range(size):\n",
    "        frase = [0] + frase\n",
    "    ngrams_list = []\n",
    "    for i in range(len(frase)-size):\n",
    "        ngrams_list.append((tuple(frase[i:i+size]),frase[i+size]))\n",
    "    return ngrams_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 180, 67, 194, 5, 780, 2095, 20, 531, 116, 871, 3, 246]\n"
     ]
    }
   ],
   "source": [
    "print(texts2ids[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "all_ngrams = []\n",
    "for i in texts2ids:\n",
    "    all_ngrams += get_ngrams(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def co_table(lista_ocurrencias):\n",
    "    table = {}\n",
    "    for i in lista_ocurrencias:\n",
    "        if i[0] in table:\n",
    "            if i[1] in table[i[0]]:\n",
    "                table[i[0]][i[1]] += 1\n",
    "            else:\n",
    "                table[i[0]][i[1]] = 1\n",
    "        else:\n",
    "            table[i[0]] = {}\n",
    "    return table\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "2355"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(co_table(all_ngrams)[(0,0)].values())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaf8493770d7c647504f8822272130844a080041caffea46428413e90a69177e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('ple': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}