{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('HerMajestySpeechesDataset/train.txt', 'r', encoding='utf-8')\n",
    "# text = f.read()\n",
    "texts = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2361"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts as IDs: [[2, 181, 999, 5, 39, 584, 41, 2094, 2095, 21, 1165, 530], [21, 9, 163, 246, 8, 1000, 25, 424, 1166, 5, 18, 20], [68, 195, 781], [2, 355, 3, 7, 1347, 722, 53, 585, 40, 213, 2, 297, 3, 531, 208, 1001], [2, 181, 68, 195, 6, 781, 2096, 21, 532, 117, 872, 4, 247], [2, 195, 49, 2097, 6, 2951, 1167, 6, 151, 224, 196, 491, 533, 2098, 197, 21, 7, 2952, 2953], [8, 13, 1168, 205, 873, 5, 114, 10, 455, 187, 298, 586, 2, 259, 11, 111, 205], [58, 3, 2, 455, 10, 29, 50, 649, 20, 10, 79, 11, 66, 12, 2, 312, 3, 68], [17, 271, 7, 59, 83, 8, 782, 5, 456, 2099, 2, 2954, 3, 2, 356, 4, 214, 10, 874, 49, 492, 5, 237, 129, 4, 493, 5, 7, 875, 42], [2, 355, 3, 783, 2100, 2955, 16, 457, 5, 20, 43, 492, 248, 4, 91, 2, 69, 2956, 11, 141]]\n",
      "IDs back to texts: [\"the queen's messages to those celebrating their 90th birthdays on 21 april\", 'on this shared occasion i send my warm congratulations to you all', 'christmas broadcast 2006', 'the birth of a baby brings great happiness but then the business of growing up begins', \"the queen's christmas broadcast in 2006 focused on understanding between faiths and generations\", 'the broadcast was filmed in southwark cathedral in london where her majesty met schoolchildren working on a nativity collage', 'i have lived long enough to know that things never remain quite the same for very long', 'one of the things that has not changed all that much for me is the celebration of christmas', 'it remains a time when i try to put aside the anxieties of the moment and remember that christ was born to bring peace and tolerance to a troubled world', 'the birth of jesus naturally turns our thoughts to all new born children and what the future holds for them']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(texts) \n",
    "\n",
    "texts2ids = tokenizer.texts_to_sequences(texts)\n",
    "print (\"Texts as IDs:\", texts2ids[:10])\n",
    "ids2texts = tokenizer.sequences_to_texts(texts2ids)\n",
    "print (\"IDs back to texts:\", ids2texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2294\n"
     ]
    }
   ],
   "source": [
    "print(len(texts2ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2): {}, (3, 4): {}, (5, 6): {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {x:{} for x in [(1,2),(3,4),(5,6)]}\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2): {'a': 1, 'b': 2}, (3, 4): {'a': 3, 'b': 4}, (5, 6): {}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(1,2)] = {'a':1, 'b':2}\n",
    "test[(3,4)] = {'a':3, 'b':4}\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocurrency_example = {\n",
    "        '': {'a':1, 'b':2},\n",
    "        'a': {'b': 1, 'c': 1},\n",
    "        ('a','b'): {'c': 1},\n",
    "        ('b','c'): {'a': 2, 'd': 1},\n",
    "        ('c','d'): {'a': 1, 'b': 1, 'c': 1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toyLM_ngram(ngram_list, ngram_sizes=[2]):\n",
    "    table_list = []\n",
    "    for size in ngram_sizes:\n",
    "        oc_table = {}\n",
    "        for i in range(len(ngram_list)-size):\n",
    "            current_ngram = ngram_list[i:i+size]\n",
    "            for current_ngram in ngram_list:\n",
    "                if current_ngram in oc_table:\n",
    "                    oc_table[current_ngram] += 1\n",
    "                else:\n",
    "                    oc_table[current_ngram] = 1\n",
    "        table_list.append(oc_table)\n",
    "        print(oc_table)\n",
    "    return table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 10, 181: 10, 999: 10, 5: 10, 39: 10, 584: 10, 41: 10, 2094: 10, 2095: 10, 21: 10, 1165: 10, 530: 10}\n",
      "[{2: 10, 181: 10, 999: 10, 5: 10, 39: 10, 584: 10, 41: 10, 2094: 10, 2095: 10, 21: 10, 1165: 10, 530: 10}]\n"
     ]
    }
   ],
   "source": [
    "print(toyLM_ngram(texts2ids[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_ngrams(frase, size=2):\n",
    "    for i in range(size):\n",
    "        frase = [0] + frase\n",
    "    ngrams_list = []\n",
    "    for i in range(len(frase)-size):\n",
    "        ngrams_list.append((tuple(frase[i:i+size]),frase[i+size]))\n",
    "    return ngrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 9, 163, 246, 8, 1000, 25, 424, 1166, 5, 18, 20]\n"
     ]
    }
   ],
   "source": [
    "print(texts2ids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_ngrams = []\n",
    "for i in texts2ids:\n",
    "    all_ngrams += get_ngrams(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def co_table(lista_ocurrencias):\n",
    "    table = {}\n",
    "    for i in lista_ocurrencias:\n",
    "        if i[0] in table:\n",
    "            if i[1] in table[i[0]]:\n",
    "                table[i[0]][i[1]] += 1\n",
    "            else:\n",
    "                table[i[0]][i[1]] = 1\n",
    "        else:\n",
    "            table[i[0]] = {}\n",
    "            table[i[0]][i[1]] = 1\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "table = co_table(all_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_toyLM_ngram_a(table, context='aleatorio', n=15):\n",
    "    if context == 'aleatorio':\n",
    "        tmp = list(table.keys())\n",
    "        context = tmp[np.random.randint(len(tmp))]\n",
    "\n",
    "    cadena = list(context)\n",
    "    for _ in range(n-len(context)):\n",
    "        context = tuple(cadena[-len(context):])\n",
    "        if context not in table.keys():\n",
    "            return tokenizer.sequences_to_texts([cadena])\n",
    "        else:\n",
    "            new = max(table[context], key=table[context].get)\n",
    "            cadena.append(new)\n",
    "    return tokenizer.sequences_to_texts([cadena])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['younger generations as they are all the more we know that the commonwealth and to']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_toyLM_ngram_a(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_toyLM_ngram_b(table, context='aleatorio', n=15):\n",
    "    if context == 'aleatorio':\n",
    "        tmp = list(table.keys())\n",
    "        context = tmp[np.random.randint(len(tmp))]\n",
    "\n",
    "    cadena = list(context)\n",
    "    for i in range(n-len(context)):\n",
    "        context = tuple(cadena[-len(context):])\n",
    "        if context not in table.keys():\n",
    "            return tokenizer.sequences_to_texts([cadena])\n",
    "        else:\n",
    "            lista_tmp = list()\n",
    "            for i in table[context]:\n",
    "                for j in range(table[context][i]):\n",
    "                    lista_tmp.append(i)\n",
    "            new = np.random.randint(len(lista_tmp))\n",
    "            cadena.append(lista_tmp[new])\n",
    "    return tokenizer.sequences_to_texts([cadena])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm congratulations on your experience with your forebears a fundamental role in parliament but all']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_toyLM_ngram_b(table, (424, 1166))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{455: 2,\n",
       " 356: 1,\n",
       " 75: 1,\n",
       " 53: 6,\n",
       " 85: 1,\n",
       " 429: 4,\n",
       " 42: 18,\n",
       " 33: 31,\n",
       " 2985: 1,\n",
       " 2988: 1,\n",
       " 184: 2,\n",
       " 31: 4,\n",
       " 1368: 1,\n",
       " 1178: 1,\n",
       " 1195: 1,\n",
       " 506: 1,\n",
       " 115: 3,\n",
       " 1684: 1,\n",
       " 255: 3,\n",
       " 2151: 1,\n",
       " 744: 5,\n",
       " 178: 2,\n",
       " 87: 14,\n",
       " 543: 5,\n",
       " 69: 7,\n",
       " 1039: 1,\n",
       " 101: 2,\n",
       " 748: 1,\n",
       " 362: 4,\n",
       " 324: 1,\n",
       " 64: 7,\n",
       " 1713: 2,\n",
       " 258: 3,\n",
       " 1716: 1,\n",
       " 2215: 1,\n",
       " 515: 1,\n",
       " 3155: 1,\n",
       " 1225: 3,\n",
       " 434: 1,\n",
       " 676: 1,\n",
       " 89: 2,\n",
       " 1427: 1,\n",
       " 216: 2,\n",
       " 2241: 1,\n",
       " 1743: 1,\n",
       " 689: 8,\n",
       " 930: 1,\n",
       " 2257: 1,\n",
       " 28: 11,\n",
       " 123: 15,\n",
       " 1080: 1,\n",
       " 3240: 1,\n",
       " 90: 2,\n",
       " 241: 2,\n",
       " 416: 2,\n",
       " 1458: 1,\n",
       " 834: 1,\n",
       " 939: 1,\n",
       " 181: 1,\n",
       " 943: 2,\n",
       " 3274: 1,\n",
       " 63: 5,\n",
       " 70: 1,\n",
       " 352: 1,\n",
       " 392: 1,\n",
       " 95: 6,\n",
       " 2325: 1,\n",
       " 3314: 1,\n",
       " 2322: 1,\n",
       " 259: 2,\n",
       " 2343: 1,\n",
       " 72: 5,\n",
       " 441: 3,\n",
       " 301: 3,\n",
       " 191: 1,\n",
       " 2371: 2,\n",
       " 194: 15,\n",
       " 134: 1,\n",
       " 1847: 1,\n",
       " 448: 3,\n",
       " 716: 2,\n",
       " 850: 3,\n",
       " 574: 2,\n",
       " 59: 1,\n",
       " 381: 2,\n",
       " 183: 1,\n",
       " 2409: 1,\n",
       " 1855: 1,\n",
       " 136: 2,\n",
       " 288: 2,\n",
       " 43: 5,\n",
       " 2411: 2,\n",
       " 1056: 1,\n",
       " 575: 5,\n",
       " 3560: 1,\n",
       " 1107: 4,\n",
       " 2418: 1,\n",
       " 107: 1,\n",
       " 1521: 1,\n",
       " 2432: 1,\n",
       " 2438: 1,\n",
       " 699: 1,\n",
       " 673: 1,\n",
       " 3610: 1,\n",
       " 1525: 1,\n",
       " 120: 3,\n",
       " 211: 2,\n",
       " 423: 2,\n",
       " 513: 1,\n",
       " 1294: 2,\n",
       " 250: 2,\n",
       " 3712: 1,\n",
       " 999: 1,\n",
       " 637: 1,\n",
       " 2283: 1,\n",
       " 791: 1,\n",
       " 855: 1,\n",
       " 1930: 1,\n",
       " 2522: 1,\n",
       " 375: 5,\n",
       " 143: 7,\n",
       " 489: 1,\n",
       " 82: 2,\n",
       " 316: 1,\n",
       " 189: 3,\n",
       " 703: 1,\n",
       " 119: 1,\n",
       " 3889: 1,\n",
       " 45: 2,\n",
       " 355: 3,\n",
       " 105: 2,\n",
       " 1958: 1,\n",
       " 764: 1,\n",
       " 1322: 2,\n",
       " 261: 1,\n",
       " 1899: 1,\n",
       " 967: 1,\n",
       " 694: 1,\n",
       " 1323: 2,\n",
       " 68: 1,\n",
       " 1574: 3,\n",
       " 98: 2,\n",
       " 2600: 1,\n",
       " 4098: 1,\n",
       " 111: 3,\n",
       " 418: 3,\n",
       " 340: 3,\n",
       " 1460: 1,\n",
       " 399: 1,\n",
       " 911: 1,\n",
       " 128: 6,\n",
       " 278: 1,\n",
       " 1863: 1,\n",
       " 124: 5,\n",
       " 951: 1,\n",
       " 1586: 2,\n",
       " 104: 1,\n",
       " 706: 1,\n",
       " 4198: 1,\n",
       " 4206: 1,\n",
       " 232: 1,\n",
       " 335: 1,\n",
       " 757: 1,\n",
       " 624: 1,\n",
       " 242: 1,\n",
       " 2658: 1,\n",
       " 892: 1,\n",
       " 4305: 1,\n",
       " 2008: 1,\n",
       " 487: 6,\n",
       " 1994: 1,\n",
       " 485: 1,\n",
       " 733: 1,\n",
       " 4380: 1,\n",
       " 158: 1,\n",
       " 99: 1,\n",
       " 979: 2,\n",
       " 151: 1,\n",
       " 286: 1,\n",
       " 350: 4,\n",
       " 220: 1,\n",
       " 73: 1,\n",
       " 1061: 1,\n",
       " 2038: 2,\n",
       " 1247: 2,\n",
       " 1770: 1,\n",
       " 4494: 1,\n",
       " 1285: 1,\n",
       " 4495: 1,\n",
       " 2751: 1,\n",
       " 474: 1,\n",
       " 830: 2,\n",
       " 2765: 2,\n",
       " 984: 2,\n",
       " 1048: 1,\n",
       " 1388: 2,\n",
       " 1036: 1,\n",
       " 311: 3,\n",
       " 2779: 2,\n",
       " 374: 1,\n",
       " 4598: 1,\n",
       " 753: 1,\n",
       " 4614: 1,\n",
       " 394: 1,\n",
       " 737: 1,\n",
       " 4628: 1,\n",
       " 376: 2,\n",
       " 332: 1,\n",
       " 1160: 1,\n",
       " 1320: 1,\n",
       " 1622: 1,\n",
       " 2795: 1,\n",
       " 195: 1,\n",
       " 153: 2,\n",
       " 1082: 1,\n",
       " 305: 1,\n",
       " 997: 2,\n",
       " 1624: 1,\n",
       " 245: 2,\n",
       " 312: 1,\n",
       " 4740: 1,\n",
       " 454: 1,\n",
       " 4761: 1,\n",
       " 4767: 1,\n",
       " 4776: 1,\n",
       " 227: 2,\n",
       " 1451: 2,\n",
       " 565: 1,\n",
       " 331: 1,\n",
       " 4823: 1,\n",
       " 975: 1,\n",
       " 1341: 1,\n",
       " 1359: 1,\n",
       " 1106: 1,\n",
       " 1625: 1,\n",
       " 1605: 1,\n",
       " 1546: 1,\n",
       " 1021: 1,\n",
       " 2207: 1,\n",
       " 353: 1,\n",
       " 2063: 2,\n",
       " 37: 1,\n",
       " 5048: 1,\n",
       " 2012: 1,\n",
       " 2058: 1,\n",
       " 1787: 1,\n",
       " 377: 1,\n",
       " 1531: 1,\n",
       " 1437: 1,\n",
       " 284: 1,\n",
       " 2820: 1,\n",
       " 146: 2,\n",
       " 304: 1,\n",
       " 708: 1,\n",
       " 1037: 1,\n",
       " 702: 1,\n",
       " 5247: 1,\n",
       " 5252: 1,\n",
       " 160: 1,\n",
       " 5281: 1,\n",
       " 827: 1,\n",
       " 218: 2,\n",
       " 1766: 1,\n",
       " 5345: 1,\n",
       " 1418: 1,\n",
       " 776: 1,\n",
       " 1986: 1,\n",
       " 1140: 1,\n",
       " 5443: 1,\n",
       " 1029: 1,\n",
       " 1164: 1,\n",
       " 583: 1,\n",
       " 1896: 1,\n",
       " 347: 1,\n",
       " 505: 1,\n",
       " 5563: 1,\n",
       " 2846: 1,\n",
       " 553: 1,\n",
       " 1209: 1,\n",
       " 789: 1,\n",
       " 1161: 1,\n",
       " 266: 1,\n",
       " 2667: 1}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[(3,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# toyLM_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_generate(text, max_seq_length=10):\n",
    "    for frase in text:\n",
    "        print(frase)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " \"queen's\",\n",
       " 'messages',\n",
       " 'to',\n",
       " 'those',\n",
       " 'celebrating',\n",
       " 'their',\n",
       " '90th',\n",
       " 'birthdays',\n",
       " 'on',\n",
       " '21',\n",
       " 'april']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids2texts[0].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})', \"(<class 'list'> containing values of types set())\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Peter\\Desktop\\Q6\\PLE\\Repositorio PLN\\main.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Peter/Desktop/Q6/PLE/Repositorio%20PLN/main.ipynb#ch0000021?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Peter/Desktop/Q6/PLE/Repositorio%20PLN/main.ipynb#ch0000021?line=1'>2</a>\u001b[0m     Embedding(\u001b[39mlen\u001b[39m(tokenizer\u001b[39m.\u001b[39mword_index)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m, input_length\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Peter/Desktop/Q6/PLE/Repositorio%20PLN/main.ipynb#ch0000021?line=2'>3</a>\u001b[0m     LSTM(\u001b[39m64\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Peter/Desktop/Q6/PLE/Repositorio%20PLN/main.ipynb#ch0000021?line=3'>4</a>\u001b[0m     Dense(\u001b[39mlen\u001b[39m(tokenizer\u001b[39m.\u001b[39mword_index)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Peter/Desktop/Q6/PLE/Repositorio%20PLN/main.ipynb#ch0000021?line=4'>5</a>\u001b[0m ])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Peter/Desktop/Q6/PLE/Repositorio%20PLN/main.ipynb#ch0000021?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Peter/Desktop/Q6/PLE/Repositorio%20PLN/main.ipynb#ch0000021?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(pad_sequences(texts2ids, maxlen\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m), texts2ids, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Peter\\Desktop\\Q6\\PLE\\ple\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Peter\\Desktop\\Q6\\PLE\\ple\\lib\\site-packages\\keras\\engine\\data_adapter.py:984\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=980'>981</a>\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=981'>982</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=982'>983</a>\u001b[0m   \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=983'>984</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=984'>985</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=985'>986</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=986'>987</a>\u001b[0m           _type_name(x), _type_name(y)))\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=987'>988</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=988'>989</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=989'>990</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=990'>991</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=991'>992</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/Peter/Desktop/Q6/PLE/ple/lib/site-packages/keras/engine/data_adapter.py?line=992'>993</a>\u001b[0m           adapter_cls, _type_name(x), _type_name(y)))\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})', \"(<class 'list'> containing values of types set())\"})"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(len(tokenizer.word_index)+1, 64, input_length=10),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dense(len(tokenizer.word_index)+1, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(pad_sequences(texts2ids, maxlen=10), texts2ids, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history ="
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaf8493770d7c647504f8822272130844a080041caffea46428413e90a69177e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('ple': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
