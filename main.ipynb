{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('HerMajestySpeechesDataset/train.txt', 'r', encoding='utf-8')\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "text = ' '.join(text.split('\\n'))\n",
    "text = ''.join(text.split('\\\\'))\n",
    "ngram_list = text.split(' ')\n",
    "\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2): {}, (3, 4): {}, (5, 6): {}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {x:{} for x in [(1,2),(3,4),(5,6)]}\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2): {'a': 1, 'b': 2}, (3, 4): {'a': 3, 'b': 4}, (5, 6): {}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(1,2)] = {'a':1, 'b':2}\n",
    "test[(3,4)] = {'a':3, 'b':4}\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocurrency_example = {\n",
    "        '': {'a':1, 'b':2},\n",
    "        'a': {'b': 1, 'c': 1},\n",
    "        ('a','b'): {'c': 1},\n",
    "        ('b','c'): {'a': 2, 'd': 1},\n",
    "        ('c','d'): {'a': 1, 'b': 1, 'c': 1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toyLM_ngram(ngram_list, ngram_sizes=[2]):\n",
    "    table_list = []\n",
    "    for size in ngram_sizes:\n",
    "        oc_table = {}\n",
    "        for i in range(len(ngram_list)-size):\n",
    "            current_ngram = ngram_list[i:i+size]\n",
    "            for current_ngram in ngram_list:\n",
    "                if current_ngram in oc_table:\n",
    "                    oc_table[current_ngram] += 1\n",
    "                else:\n",
    "                    oc_table[current_ngram] = 1\n",
    "        table_list.append(oc_table)\n",
    "        print(oc_table)\n",
    "    return table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyLM_ngram(ngram_list, ngram_sizes=[2,3])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaf8493770d7c647504f8822272130844a080041caffea46428413e90a69177e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('ple': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
